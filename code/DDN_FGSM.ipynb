{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDN_FGSM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hvWlU8yaRcG1",
        "c15Tg33hQsE4",
        "rSapYSxn78kg",
        "b68Bk9oH70th"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AE3cxok5Vef"
      },
      "source": [
        "# CS470 Code (DDN-FGSM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vrVtzpeIHKt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8766601e-af2c-4fdc-d4b7-412ab5b13994"
      },
      "source": [
        "# login with your google account and type authorization code to mount on your google drive.\n",
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad_6DYDX5Ovx"
      },
      "source": [
        "## Implementation of Network\r\n",
        "\r\n",
        "You can use different network. We use GoogLeNet, but you may change it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvWlU8yaRcG1"
      },
      "source": [
        "### Implement WideResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-V4JdM-RcZz"
      },
      "source": [
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#from src.utils import count_parameters\n",
        "\n",
        "class Expression(nn.Module):\n",
        "    def __init__(self, func):\n",
        "        super(Expression, self).__init__()\n",
        "        self.func = func\n",
        "    \n",
        "    def forward(self, input):\n",
        "        return self.func(input)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, i_c=1, n_c=10):\n",
        "        super(Model, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(i_c, 32, 5, stride=1, padding=2, bias=True)\n",
        "        self.pool1 = nn.MaxPool2d((2, 2), stride=(2, 2), padding=0)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, 5, stride=1, padding=2, bias=True)\n",
        "        self.pool2 = nn.MaxPool2d((2, 2), stride=(2, 2), padding=0)\n",
        "\n",
        "\n",
        "        self.flatten = Expression(lambda tensor: tensor.view(tensor.shape[0], -1))\n",
        "        self.fc1 = nn.Linear(7 * 7 * 64, 1024, bias=True)\n",
        "        self.fc2 = nn.Linear(1024, n_c)\n",
        "\n",
        "\n",
        "    def forward(self, x_i, _eval=False):\n",
        "\n",
        "        if _eval:\n",
        "            # switch to eval mode\n",
        "            self.eval()\n",
        "        else:\n",
        "            self.train()\n",
        "            \n",
        "        x_o = self.conv1(x_i)\n",
        "        x_o = torch.relu(x_o)\n",
        "        x_o = self.pool1(x_o)\n",
        "\n",
        "        x_o = self.conv2(x_o)\n",
        "        x_o = torch.relu(x_o)\n",
        "        x_o = self.pool2(x_o)\n",
        "\n",
        "        x_o = self.flatten(x_o)\n",
        "\n",
        "        x_o = torch.relu(self.fc1(x_o))\n",
        "\n",
        "        self.train()\n",
        "\n",
        "        return self.fc2(x_o)\n",
        "\n",
        "class ChannelPadding(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes):\n",
        "        super(ChannelPadding, self).__init__()\n",
        "\n",
        "        self.register_buffer(\"padding\", \n",
        "                             torch.zeros((out_planes - in_planes) // 2).view(1, -1, 1, 1))\n",
        "\n",
        "    def forward(self, input):\n",
        "        assert len(input.size()) == 4, \"only support for 4-D tensor for now\"\n",
        "\n",
        "        padding = self.padding.expand(input.size(0), -1, input.size(2), input.size(3))\n",
        "\n",
        "        return torch.cat([padding, input, padding], dim=1)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.LeakyReLU(0.1, inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.LeakyReLU(0.1, inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        # self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "        #                        padding=0, bias=False) or None\n",
        "        self.poolpadShortcut = nn.Sequential(\n",
        "            nn.AvgPool2d(kernel_size=stride, stride=stride),\n",
        "            ChannelPadding(in_planes, out_planes)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        # return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "        return torch.add(\n",
        "            x if self.equalInOut else self.poolpadShortcut(x),\n",
        "            out\n",
        "        )\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(int(nb_layers)):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth, num_classes, widen_factor=1, dropRate=0.0):\n",
        "        super(WideResNet, self).__init__()\n",
        "        nChannels = [16, 16*widen_factor, 32*widen_factor, 64*widen_factor]\n",
        "        assert((depth - 4) % 6 == 0)\n",
        "        n = (depth - 4) / 6\n",
        "        block = BasicBlock\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, 1, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and classifier\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.LeakyReLU(0.1, inplace=True)\n",
        "        self.fc = nn.Linear(nChannels[3], num_classes)\n",
        "        self.nChannels = nChannels[3]\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, _eval=False):\n",
        "        if _eval:\n",
        "            # switch to eval mode\n",
        "            self.eval()\n",
        "        else:\n",
        "            self.train()\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.block1(out)\n",
        "        out = self.block2(out)\n",
        "        out = self.block3(out)\n",
        "        out = self.relu(self.bn1(out))\n",
        "        out = F.avg_pool2d(out, 8)\n",
        "        out = out.view(-1, self.nChannels)\n",
        "\n",
        "        self.train()\n",
        "\n",
        "        return self.fc(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c15Tg33hQsE4"
      },
      "source": [
        "### Implement ResNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52h-mw_4QsWk"
      },
      "source": [
        "# 3x3 convolution\n",
        "def conv3x3(in_channels, out_channels, stride=1):\n",
        "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, \n",
        "                     stride=stride, padding=1, bias=False)\n",
        "\n",
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_channels, out_channels, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_channels, out_channels)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# ResNet\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = conv3x3(3, 16)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0])\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], 2)\n",
        "        self.layer3 = self.make_layer(block, 64, layers[2], 2)\n",
        "        self.avg_pool = nn.AvgPool2d(8)\n",
        "        self.fc = nn.Linear(64, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                conv3x3(self.in_channels, out_channels, stride=stride),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x, _eval=False):\n",
        "        if _eval:\n",
        "            # switch to eval mode\n",
        "            self.eval()\n",
        "        else:\n",
        "            self.train()\n",
        "            \n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSapYSxn78kg"
      },
      "source": [
        "### Implement GoogLeNet\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6yxRyCL2y5R"
      },
      "source": [
        "class Inception(nn.Module):\n",
        "    def __init__(self, in_planes, kernel_1_x, kernel_3_in, kernel_3_x, kernel_5_in, kernel_5_x, pool_planes):\n",
        "        super(Inception, self).__init__()\n",
        "        # 1x1 conv branch\n",
        "        self.b1 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, kernel_1_x, kernel_size=1),\n",
        "            nn.BatchNorm2d(kernel_1_x),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 3x3 conv branch\n",
        "        self.b2 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, kernel_3_in, kernel_size=1),\n",
        "            nn.BatchNorm2d(kernel_3_in),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(kernel_3_in, kernel_3_x, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(kernel_3_x),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 1x1 conv -> 5x5 conv branch\n",
        "        self.b3 = nn.Sequential(\n",
        "            nn.Conv2d(in_planes, kernel_5_in, kernel_size=1),\n",
        "            nn.BatchNorm2d(kernel_5_in),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(kernel_5_in, kernel_5_x, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(kernel_5_x),\n",
        "            nn.ReLU(True),\n",
        "            nn.Conv2d(kernel_5_x, kernel_5_x, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(kernel_5_x),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        # 3x3 pool -> 1x1 conv branch\n",
        "        self.b4 = nn.Sequential(\n",
        "            nn.MaxPool2d(3, stride=1, padding=1),\n",
        "            nn.Conv2d(in_planes, pool_planes, kernel_size=1),\n",
        "            nn.BatchNorm2d(pool_planes),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        y1 = self.b1(x)\n",
        "        y2 = self.b2(x)\n",
        "        y3 = self.b3(x)\n",
        "        y4 = self.b4(x)\n",
        "        return torch.cat([y1,y2,y3,y4], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jx7IlEO21Es"
      },
      "source": [
        "class GoogLeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GoogLeNet, self).__init__()\n",
        "        self.pre_layers = nn.Sequential(\n",
        "            nn.Conv2d(3, 192, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(192),\n",
        "            nn.ReLU(True),\n",
        "        )\n",
        "\n",
        "        self.a3 = Inception(192,  64,  96, 128, 16, 32, 32)\n",
        "        self.b3 = Inception(256, 128, 128, 192, 32, 96, 64)\n",
        "\n",
        "        self.max_pool = nn.MaxPool2d(3, stride=2, padding=1)\n",
        "\n",
        "        self.a4 = Inception(480, 192,  96, 208, 16,  48,  64)\n",
        "        self.b4 = Inception(512, 160, 112, 224, 24,  64,  64)\n",
        "        self.c4 = Inception(512, 128, 128, 256, 24,  64,  64)\n",
        "        self.d4 = Inception(512, 112, 144, 288, 32,  64,  64)\n",
        "        self.e4 = Inception(528, 256, 160, 320, 32, 128, 128)\n",
        "\n",
        "        self.a5 = Inception(832, 256, 160, 320, 32, 128, 128)\n",
        "        self.b5 = Inception(832, 384, 192, 384, 48, 128, 128)\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(8, stride=1)\n",
        "        self.linear = nn.Linear(1024, 10)\n",
        "\n",
        "    def forward(self, x, _eval=False):\n",
        "        if _eval:\n",
        "            # switch to eval mode\n",
        "            self.eval()\n",
        "        else:\n",
        "            self.train()\n",
        "        \n",
        "        x = self.pre_layers(x)\n",
        "        x = self.a3(x)\n",
        "        x = self.b3(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.a4(x)\n",
        "        x = self.b4(x)\n",
        "        x = self.c4(x)\n",
        "        x = self.d4(x)\n",
        "        x = self.e4(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.a5(x)\n",
        "        x = self.b5(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.linear(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b68Bk9oH70th"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asWMjApm72RK"
      },
      "source": [
        "import os\n",
        "import json\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "class LabelDict():\n",
        "    def __init__(self, dataset='cifar-10'):\n",
        "        self.dataset = dataset\n",
        "        if dataset == 'cifar-10':\n",
        "            self.label_dict = {0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', \n",
        "                         4: 'deer',     5: 'dog',        6: 'frog', 7: 'horse',\n",
        "                         8: 'ship',     9: 'truck'}\n",
        "\n",
        "        self.class_dict = {v: k for k, v in self.label_dict.items()}\n",
        "\n",
        "    def label2class(self, label):\n",
        "        assert label in self.label_dict, 'the label %d is not in %s' % (label, self.dataset)\n",
        "        return self.label_dict[label]\n",
        "\n",
        "    def class2label(self, _class):\n",
        "        assert isinstance(_class, str)\n",
        "        assert _class in self.class_dict, 'the class %s is not in %s' % (_class, self.dataset)\n",
        "        return self.class_dict[_class]\n",
        "\n",
        "def list2cuda(_list):\n",
        "    array = np.array(_list)\n",
        "    return numpy2cuda(array)\n",
        "\n",
        "def numpy2cuda(array):\n",
        "    tensor = torch.from_numpy(array)\n",
        "\n",
        "    return tensor2cuda(tensor)\n",
        "\n",
        "def tensor2cuda(tensor):\n",
        "    if torch.cuda.is_available():\n",
        "        tensor = tensor.cuda()\n",
        "\n",
        "    return tensor\n",
        "\n",
        "def one_hot(ids, n_class):\n",
        "    # --------------------- \n",
        "    # author：ke1th \n",
        "    # source：CSDN \n",
        "    # artical：https://blog.csdn.net/u012436149/article/details/77017832 \n",
        "    b\"\"\"\n",
        "    ids: (list, ndarray) shape:[batch_size]\n",
        "    out_tensor:FloatTensor shape:[batch_size, depth]\n",
        "    \"\"\"\n",
        "\n",
        "    assert len(ids.shape) == 1, 'the ids should be 1-D'\n",
        "    # ids = torch.LongTensor(ids).view(-1,1) \n",
        "\n",
        "    out_tensor = torch.zeros(len(ids), n_class)\n",
        "\n",
        "    out_tensor.scatter_(1, ids.cpu().unsqueeze(1), 1.)\n",
        "\n",
        "    return out_tensor\n",
        "    \n",
        "def evaluate(_input, _target, method='mean'):\n",
        "    correct = (_input == _target).astype(np.float32)\n",
        "    if method == 'mean':\n",
        "        return correct.mean()\n",
        "    else:\n",
        "        return correct.sum()\n",
        "\n",
        "\n",
        "def create_logger(save_path='', file_type='', level='debug'):\n",
        "\n",
        "    if level == 'debug':\n",
        "        _level = logging.DEBUG\n",
        "    elif level == 'info':\n",
        "        _level = logging.INFO\n",
        "\n",
        "    logger = logging.getLogger()\n",
        "    logger.setLevel(_level)\n",
        "\n",
        "    cs = logging.StreamHandler()\n",
        "    cs.setLevel(_level)\n",
        "    logger.addHandler(cs)\n",
        "\n",
        "    if save_path != '':\n",
        "        file_name = os.path.join(save_path, file_type + '_log.txt')\n",
        "        fh = logging.FileHandler(file_name, mode='w')\n",
        "        fh.setLevel(_level)\n",
        "\n",
        "        logger.addHandler(fh)\n",
        "\n",
        "    return logger\n",
        "\n",
        "def makedirs(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "def load_model(model, file_name):\n",
        "    model.load_state_dict(\n",
        "            torch.load(file_name, map_location=lambda storage, loc: storage))\n",
        "\n",
        "def save_model(model, file_name):\n",
        "    torch.save(model.state_dict(), file_name)\n",
        "\n",
        "def count_parameters(model):\n",
        "    # copy from https://discuss.pytorch.org/t/how-do-i-check-the-number-of-parameters-of-a-model/4325/8\n",
        "    # baldassarre.fe's reply\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjxKUBoXFGgn"
      },
      "source": [
        "\"\"\"\n",
        "this code is modified from https://github.com/utkuozbulak/pytorch-cnn-visualizations\n",
        "original author: Utku Ozbulak - github.com/utkuozbulak\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import torch\n",
        "\n",
        "class VanillaBackprop():\n",
        "    \"\"\"\n",
        "        Produces gradients generated with vanilla back propagation from the image\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def generate_gradients(self, input_image, target_class):\n",
        "        # Put model in evaluation mode\n",
        "        self.model.eval()\n",
        "\n",
        "        x = input_image.clone()\n",
        "\n",
        "        x.requires_grad = True\n",
        "\n",
        "        with torch.enable_grad():\n",
        "            # Forward\n",
        "            model_output = self.model(x)\n",
        "            # Zero grads\n",
        "            self.model.zero_grad()\n",
        "            \n",
        "            grad_outputs = one_hot(target_class, model_output.shape[1])\n",
        "            grad_outputs = tensor2cuda(grad_outputs)\n",
        "\n",
        "            grad = torch.autograd.grad(model_output, x, grad_outputs=grad_outputs, \n",
        "                        only_inputs=True)[0]\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "        return grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx3ePw8l313U"
      },
      "source": [
        "## Parser: Set Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mzw5lZ5l32s2"
      },
      "source": [
        "import argparse\n",
        "\n",
        "def parser():\n",
        "    parser = argparse.ArgumentParser(description='Video Summarization')\n",
        "    parser.add_argument('--todo', choices=['train', 'valid', 'test', 'visualize'], default='train',\n",
        "        help='what behavior want to do: train | valid | test | visualize')\n",
        "    parser.add_argument('--dataset', default='cifar-10', help='use what dataset')\n",
        "    parser.add_argument('--data_root', default='/gdrive/My Drive/test/data_dir', \n",
        "        help='the directory to save the dataset')\n",
        "    parser.add_argument('--log_root', default='/gdrive/My Drive/test/log_dir', \n",
        "        help='the directory to save the logs or other imformations (e.g. images)')\n",
        "    parser.add_argument('--model_root', default='/gdrive/My Drive/test/checkpoint_dir', help='the directory to save the models')\n",
        "    parser.add_argument('--load_checkpoint', default='/gdrive/My Drive/test/model/model.pth')\n",
        "    parser.add_argument('--affix', default='default', help='the affix for the save folder')\n",
        "\n",
        "    # parameters for generating adversarial examples\n",
        "    parser.add_argument('--epsilon', '-e', type=float, default=0.0157, \n",
        "        help='maximum perturbation of adversaries (4/255=0.0157)')\n",
        "    parser.add_argument('--alpha', '-a', type=float, default=0.00784, \n",
        "        help='movement multiplier per iteration when generating adversarial examples (2/255=0.00784)')\n",
        "    parser.add_argument('--k', '-k', type=int, default=10, \n",
        "        help='maximum iteration when generating adversarial examples')\n",
        "\n",
        "    parser.add_argument('--batch_size', '-b', type=int, default=128, help='batch size')\n",
        "    parser.add_argument('--max_epoch', '-m_e', type=int, default=30, \n",
        "        help='the maximum numbers of the model see a sample')\n",
        "    parser.add_argument('--learning_rate', '-lr', type=float, default=0.1, help='learning rate')\n",
        "    parser.add_argument('--momentum', '-m', type=float, default=0.9, help='momentum for optimizer')\n",
        "    parser.add_argument('--weight_decay', '-w', type=float, default=2e-4, \n",
        "        help='the parameter of l2 restriction for weights')\n",
        "\n",
        "    parser.add_argument('--gpu', '-g', default='0', help='which gpu to use')\n",
        "    parser.add_argument('--n_eval_step', type=int, default=100, \n",
        "        help='number of iteration per one evaluation')\n",
        "    parser.add_argument('--n_checkpoint_step', type=int, default=4000, \n",
        "        help='number of iteration to save a checkpoint')\n",
        "    parser.add_argument('--n_store_image_step', type=int, default=4000, \n",
        "        help='number of iteration to save adversaries')\n",
        "    parser.add_argument('--perturbation_type', '-p', choices=['linf', 'l2'], default='linf', \n",
        "        help='the type of the perturbation (linf or l2)')\n",
        "    \n",
        "    parser.add_argument('--adv_train', default=True, action='store_true')\n",
        "\n",
        "    parser.add_argument('--train_attack_type', choices=['fgsm', 'ddn', 'cmplx', 'avg'], default=\"avg\")\n",
        "\n",
        "    parser.add_argument('--test_attack_type', choices=['fgsm', 'ddn'], default=\"ddn\")\n",
        "\n",
        "    return parser.parse_args()\n",
        "\n",
        "def print_args(args, logger=None):\n",
        "    for k, v in vars(args).items():\n",
        "        if logger is not None:\n",
        "            logger.info('{:<16} : {}'.format(k, v))\n",
        "        else:\n",
        "            print('{:<16} : {}'.format(k, v))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaqMnNQOE9fH"
      },
      "source": [
        "## Attacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo6uTvfuE_jS"
      },
      "source": [
        "# FGSM - Untargeted\n",
        "\"\"\"\n",
        "this code is modified from https://github.com/utkuozbulak/pytorch-cnn-adversarial-attacks\n",
        "original author: Utku Ozbulak - github.com/utkuozbulak\n",
        "\"\"\"\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def project(x, original_x, epsilon, _type='linf'):\n",
        "\n",
        "    if _type == 'linf':\n",
        "        max_x = original_x + epsilon\n",
        "        min_x = original_x - epsilon\n",
        "\n",
        "        x = torch.max(torch.min(x, max_x), min_x)\n",
        "\n",
        "    elif _type == 'l2':\n",
        "        dist = (x - original_x)\n",
        "\n",
        "        dist = dist.view(x.shape[0], -1)\n",
        "\n",
        "        dist_norm = torch.norm(dist, dim=1, keepdim=True)\n",
        "\n",
        "        mask = (dist_norm > epsilon).unsqueeze(2).unsqueeze(3)\n",
        "\n",
        "        # dist = F.normalize(dist, p=2, dim=1)\n",
        "\n",
        "        dist = dist / dist_norm\n",
        "\n",
        "        dist *= epsilon\n",
        "\n",
        "        dist = dist.view(x.shape)\n",
        "\n",
        "        x = (original_x + dist) * mask.float() + x * (1 - mask.float())\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    return x\n",
        "\n",
        "class FastGradientSignUntargeted():\n",
        "    b\"\"\"\n",
        "        Fast gradient sign untargeted adversarial attack, minimizes the initial class activation\n",
        "        with iterative grad sign updates\n",
        "    \"\"\"\n",
        "    def __init__(self, model, epsilon, alpha, min_val, max_val, max_iters, _type='linf'):\n",
        "        self.model = model\n",
        "        # self.model.eval()\n",
        "\n",
        "        # Maximum perturbation\n",
        "        self.epsilon = epsilon\n",
        "        # Movement multiplier per iteration\n",
        "        self.alpha = alpha\n",
        "        # Minimum value of the pixels\n",
        "        self.min_val = min_val\n",
        "        # Maximum value of the pixels\n",
        "        self.max_val = max_val\n",
        "        # Maximum numbers of iteration to generated adversaries\n",
        "        self.max_iters = max_iters\n",
        "        # The perturbation of epsilon\n",
        "        self._type = _type\n",
        "        \n",
        "    def perturb(self, original_images, labels, reduction4loss='mean', random_start=False):\n",
        "        # original_images: values are within self.min_val and self.max_val\n",
        "\n",
        "        # The adversaries created from random close points to the original data\n",
        "        if random_start:\n",
        "            rand_perturb = torch.FloatTensor(original_images.shape).uniform_(\n",
        "                -self.epsilon, self.epsilon)\n",
        "            rand_perturb = tensor2cuda(rand_perturb)\n",
        "            x = original_images + rand_perturb\n",
        "            x.clamp_(self.min_val, self.max_val)\n",
        "        else:\n",
        "            x = original_images.clone()\n",
        "\n",
        "        x.requires_grad = True \n",
        "\n",
        "        # max_x = original_images + self.epsilon\n",
        "        # min_x = original_images - self.epsilon\n",
        "\n",
        "        self.model.eval()\n",
        "\n",
        "        with torch.enable_grad():\n",
        "            for _iter in range(self.max_iters):\n",
        "                outputs = self.model(x)\n",
        "\n",
        "                loss = F.cross_entropy(outputs, labels, reduction=reduction4loss)\n",
        "\n",
        "                if reduction4loss == 'none':\n",
        "                    grad_outputs = tensor2cuda(torch.ones(loss.shape))\n",
        "                    \n",
        "                else:\n",
        "                    grad_outputs = None\n",
        "\n",
        "                grads = torch.autograd.grad(loss, x, grad_outputs=grad_outputs, \n",
        "                        only_inputs=True)[0]\n",
        "\n",
        "                x.data += self.alpha * torch.sign(grads.data) \n",
        "\n",
        "                # the adversaries' pixel value should within max_x and min_x due \n",
        "                # to the l_infinity / l2 restriction\n",
        "                x = project(x, original_images, self.epsilon, self._type)\n",
        "                # the adversaries' value should be valid pixel value\n",
        "                x.clamp_(self.min_val, self.max_val)\n",
        "\n",
        "        self.model.train()\n",
        "\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vdc5z09hT1g4"
      },
      "source": [
        "# PGD\n",
        "\n",
        "class ProjectedGradientDescent():\n",
        "    b\"\"\"\n",
        "        Projected gradient descent adversarial attack\n",
        "    \"\"\"\n",
        "    def __init__(self, model, epsilon, alpha, min_val, max_val, max_iters, _type='linf'):\n",
        "        self.model = model\n",
        "        # self.model.eval()\n",
        "\n",
        "        # Maximum perturbation\n",
        "        self.epsilon = epsilon\n",
        "        # Movement multiplier per iteration\n",
        "        self.alpha = alpha\n",
        "        # Minimum value of the pixels\n",
        "        self.min_val = min_val\n",
        "        # Maximum value of the pixels\n",
        "        self.max_val = max_val\n",
        "        # Maximum numbers of iteration to generated adversaries\n",
        "        self.max_iters = max_iters\n",
        "        # The perturbation of epsilon\n",
        "        self._type = _type\n",
        "        \n",
        "    def perturb(self, original_images, labels, step_size, step_norm, eps_norm, reduction4loss='mean', random_start=False):\n",
        "        if random_start:\n",
        "            rand_perturb = torch.FloatTensor(original_images.shape).uniform_(\n",
        "                -self.epsilon, self.epsilon)\n",
        "            rand_perturb = tensor2cuda(rand_perturb)\n",
        "            x_adv = original_images + rand_perturb\n",
        "            x_adv.clamp_(self.min_val, self.max_val)\n",
        "        else:\n",
        "            x_adv = original_images.clone().detach().requires_grad_(True).to(original_images.device)\n",
        "        \n",
        "        num_channels = original_images.shape[1]\n",
        "\n",
        "        for i in range(self.max_iters):\n",
        "            _x_adv = x_adv.clone().detach().requires_grad_(True)\n",
        "\n",
        "            predictions = self.model(_x_adv)\n",
        "            loss = F.cross_entropy(predictions, labels, reduction=reduction4loss)\n",
        "            loss.backward()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Force the gradient step to be a fixed size in a certain norm\n",
        "                if step_norm == 'inf':\n",
        "                    gradients = _x_adv.grad.sign() * step_size\n",
        "                else:\n",
        "                    # Note .view() assumes batched image data as 4D tensor\n",
        "                    gradients = _x_adv.grad * step_size / _x_adv.grad.view(_x_adv.shape[0], -1)\\\n",
        "                        .norm(step_norm, dim=-1)\\\n",
        "                        .view(-1, num_channels, 1, 1)\n",
        "\n",
        "                x_adv += gradients\n",
        "\n",
        "            # Project back into l_norm ball and correct range\n",
        "            if eps_norm == 'inf':\n",
        "                # Workaround as PyTorch doesn't have elementwise clip\n",
        "                x_adv = torch.max(torch.min(x_adv, original_images + self.epsilon), original_images - self.epsilon)\n",
        "            else:\n",
        "                delta = x_adv - original_images\n",
        "\n",
        "                # Assume x and x_adv are batched tensors where the first dimension is\n",
        "                # a batch dimension\n",
        "                mask = delta.view(delta.shape[0], -1).norm(norm, dim=1) <= self.epsilon\n",
        "\n",
        "                scaling_factor = delta.view(delta.shape[0], -1).norm(norm, dim=1)\n",
        "                scaling_factor[mask] = self.epsilon\n",
        "\n",
        "                # .view() assumes batched images as a 4D Tensor\n",
        "                delta *= self.epsilon / scaling_factor.view(-1, 1, 1, 1)\n",
        "\n",
        "                x_adv = original_images + delta\n",
        "                \n",
        "            x_adv = x_adv.clamp(self.min_val, self.max_val)\n",
        "\n",
        "        return x_adv.detach()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiOBUuHr0sMT"
      },
      "source": [
        "#Deepfool\n",
        "\n",
        "class Deepfool():\n",
        "    def __init__(self, model, epsilon, max_iters):\n",
        "        self.model = model\n",
        "        # self.model.eval()\n",
        "\n",
        "        # Maximum perturbation\n",
        "        self.epsilon = epsilon\n",
        "        # Maximum numbers of iteration to generated adversaries\n",
        "        self.max_iters = max_iters\n",
        "        \n",
        "    def perturb(self, images, labels, reduction4loss='mean', random_start=False, num_classes=10):  # overshoot is epsilon\n",
        "\n",
        "        is_cuda = torch.cuda.is_available()\n",
        "\n",
        "        pert_images = []\n",
        "\n",
        "        net = self.model\n",
        "        overshoot = self.epsilon\n",
        "        max_iter=self.max_iters\n",
        "\n",
        "        for image in images:\n",
        "\n",
        "          if is_cuda:\n",
        "              # print(\"Using GPU\")\n",
        "              image = image.cuda()\n",
        "              net = net.cuda()\n",
        "          # else:\n",
        "          #     print(\"Using CPU\")\n",
        "\n",
        "\n",
        "          f_image = net.forward(Variable(image[None, :, :, :], requires_grad=True)).data.cpu().numpy().flatten()\n",
        "          I = (np.array(f_image)).flatten().argsort()[::-1]\n",
        "          \n",
        "          I = I[0:num_classes]\n",
        "          label = I[0]\n",
        "\n",
        "          input_shape = image.cpu().numpy().shape\n",
        "          pert_image = copy.deepcopy(image)\n",
        "          w = np.zeros(input_shape)\n",
        "          r_tot = np.zeros(input_shape)\n",
        "\n",
        "          loop_i = 0\n",
        "\n",
        "          x = Variable(pert_image[None, :], requires_grad=True)\n",
        "          fs = net.forward(x)\n",
        "          fs_list = [fs[0,I[k]] for k in range(num_classes)]\n",
        "          k_i = label\n",
        "\n",
        "          while k_i == label and loop_i < max_iter:\n",
        "\n",
        "              pert = np.inf\n",
        "              fs[0, I[0]].backward(retain_graph=True)\n",
        "              grad_orig = x.grad.data.cpu().numpy().copy()\n",
        "\n",
        "              for k in range(1, num_classes):\n",
        "                  zero_gradients(x)\n",
        "\n",
        "                  fs[0, I[k]].backward(retain_graph=True)\n",
        "                  cur_grad = x.grad.data.cpu().numpy().copy()\n",
        "\n",
        "                  # set new w_k and new f_k\n",
        "                  w_k = cur_grad - grad_orig\n",
        "                  f_k = (fs[0, I[k]] - fs[0, I[0]]).data.cpu().numpy()\n",
        "\n",
        "                  pert_k = abs(f_k)/np.linalg.norm(w_k.flatten())\n",
        "\n",
        "                  # determine which w_k to use\n",
        "                  if pert_k < pert:\n",
        "                      pert = pert_k\n",
        "                      w = w_k\n",
        "\n",
        "              # compute r_i and r_tot\n",
        "              # Added 1e-4 for numerical stability\n",
        "              r_i =  (pert+1e-4) * w / np.linalg.norm(w)\n",
        "              r_tot = np.float32(r_tot + r_i)\n",
        "\n",
        "              if is_cuda:\n",
        "                  pert_image = image + (1+overshoot)*torch.from_numpy(r_tot).cuda()\n",
        "              else:\n",
        "                  pert_image = image + (1+overshoot)*torch.from_numpy(r_tot)\n",
        "\n",
        "              x = Variable(pert_image, requires_grad=True)\n",
        "              fs = net.forward(x)\n",
        "              k_i = np.argmax(fs.data.cpu().numpy().flatten())\n",
        "\n",
        "              loop_i += 1\n",
        "\n",
        "          r_tot = (1+overshoot)*r_tot\n",
        "\n",
        "          pert_images.append(pert_image)\n",
        "        return torch.cat(pert_images)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4E8FeX9hoyn"
      },
      "source": [
        "from typing import Optional\n",
        "\n",
        "class DDN():\n",
        "    \"\"\"\n",
        "    DDN attack: decoupling the direction and norm of the perturbation to achieve a small L2 norm in few steps.\n",
        "    Parameters\n",
        "    ----------\n",
        "    steps : int\n",
        "        Number of steps for the optimization.\n",
        "    gamma : float, optional\n",
        "        Factor by which the norm will be modified. new_norm = norm * (1 + or - gamma).\n",
        "    init_norm : float, optional\n",
        "        Initial value for the norm.\n",
        "    quantize : bool, optional\n",
        "        If True, the returned adversarials will have quantized values to the specified number of levels.\n",
        "    levels : int, optional\n",
        "        Number of levels to use for quantization (e.g. 256 for 8 bit images).\n",
        "    max_norm : float or None, optional\n",
        "        If specified, the norms of the perturbations will not be greater than this value which might lower success rate.\n",
        "    device : torch.device, optional\n",
        "        Device on which to perform the attack.\n",
        "    callback : object, optional\n",
        "        Visdom callback to display various metrics.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model: nn.Module,\n",
        "                 steps: int,\n",
        "                 gamma: float = 0.05,\n",
        "                 init_norm: float = 1.,\n",
        "                 quantize: bool = True,\n",
        "                 levels: int = 256,\n",
        "                 max_norm: Optional[float] = None,\n",
        "                 device: torch.device = torch.device('cpu'),\n",
        "                 callback: Optional = None) -> None:\n",
        "        self.model = model\n",
        "        self.steps = steps\n",
        "        self.gamma = gamma\n",
        "        self.init_norm = init_norm\n",
        "\n",
        "        self.quantize = quantize\n",
        "        self.levels = levels\n",
        "        self.max_norm = max_norm\n",
        "\n",
        "        self.device = device\n",
        "        self.callback = callback\n",
        "\n",
        "    def perturb(self, inputs: torch.Tensor, labels: torch.Tensor,\n",
        "               targeted: bool = False) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Performs the attack of the model for the inputs and labels.\n",
        "        Parameters\n",
        "        ----------\n",
        "        model : nn.Module\n",
        "            Model to attack.\n",
        "        inputs : torch.Tensor\n",
        "            Batch of samples to attack. Values should be in the [0, 1] range.\n",
        "        labels : torch.Tensor\n",
        "            Labels of the samples to attack if untargeted, else labels of targets.\n",
        "        targeted : bool, optional\n",
        "            Whether to perform a targeted attack or not.\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Batch of samples modified to be adversarial to the model.\n",
        "        \"\"\"\n",
        "        if inputs.min() < 0 or inputs.max() > 1: raise ValueError('Input values should be in the [0, 1] range.')\n",
        "\n",
        "        batch_size = inputs.shape[0]\n",
        "        multiplier = 1 if targeted else -1\n",
        "        delta = torch.zeros_like(inputs, requires_grad=True)\n",
        "        norm = torch.full((batch_size,), self.init_norm, device=self.device, dtype=torch.float)\n",
        "        worst_norm = torch.max(inputs, 1 - inputs).view(batch_size, -1).norm(p=2, dim=1)\n",
        "\n",
        "        # Setup optimizers\n",
        "        optimizer = optim.SGD([delta], lr=1)\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.steps, eta_min=0.01)\n",
        "\n",
        "        best_l2 = worst_norm.clone()\n",
        "        best_delta = torch.zeros_like(inputs)\n",
        "        adv_found = torch.zeros(inputs.size(0), dtype=torch.uint8, device=self.device)\n",
        "\n",
        "        for i in range(self.steps):\n",
        "            scheduler.step()\n",
        "\n",
        "            l2 = delta.data.view(batch_size, -1).norm(p=2, dim=1)\n",
        "            adv = inputs + delta\n",
        "            logits = self.model(adv)\n",
        "            pred_labels = logits.argmax(1)\n",
        "            ce_loss = F.cross_entropy(logits, labels, reduction='sum')\n",
        "            loss = multiplier * ce_loss\n",
        "\n",
        "            is_adv = (pred_labels == labels) if targeted else (pred_labels != labels)\n",
        "            is_smaller = l2 < best_l2\n",
        "            is_both = is_adv * is_smaller\n",
        "            adv_found[is_both] = 1\n",
        "            best_l2[is_both] = l2[is_both]\n",
        "            best_delta[is_both] = delta.data[is_both]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            # renorming gradient\n",
        "            grad_norms = delta.grad.view(batch_size, -1).norm(p=2, dim=1)\n",
        "            delta.grad.div_(grad_norms.view(-1, 1, 1, 1))\n",
        "            # avoid nan or inf if gradient is 0\n",
        "            if (grad_norms == 0).any():\n",
        "                delta.grad[grad_norms == 0] = torch.randn_like(delta.grad[grad_norms == 0])\n",
        "\n",
        "            if self.callback:\n",
        "                cosine = F.cosine_similarity(-delta.grad.view(batch_size, -1),\n",
        "                                             delta.data.view(batch_size, -1), dim=1).mean().item()\n",
        "                self.callback.scalar('ce', i, ce_loss.item() / batch_size)\n",
        "                self.callback.scalars(\n",
        "                    ['max_norm', 'l2', 'best_l2'], i,\n",
        "                    [norm.mean().item(), l2.mean().item(),\n",
        "                     best_l2[adv_found].mean().item() if adv_found.any() else norm.mean().item()]\n",
        "                )\n",
        "                self.callback.scalars(['cosine', 'lr', 'success'], i,\n",
        "                                      [cosine, optimizer.param_groups[0]['lr'], adv_found.float().mean().item()])\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            norm.mul_(1 - (2 * is_adv.float() - 1) * self.gamma)\n",
        "            norm = torch.min(norm, worst_norm)\n",
        "\n",
        "            delta.data.mul_((norm / delta.data.view(batch_size, -1).norm(2, 1)).view(-1, 1, 1, 1))\n",
        "            delta.data.add_(inputs)\n",
        "            if self.quantize:\n",
        "                delta.data.mul_(self.levels - 1).round_().div_(self.levels - 1)\n",
        "            delta.data.clamp_(0, 1).sub_(inputs)\n",
        "\n",
        "        if self.max_norm:\n",
        "            best_delta.renorm_(p=2, dim=0, maxnorm=self.max_norm)\n",
        "            if self.quantize:\n",
        "                best_delta.mul_(self.levels - 1).round_().div_(self.levels - 1)\n",
        "\n",
        "        return inputs + best_delta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NF_gezqG9AXX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZIRpv899Byj"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision as tv\n",
        "\n",
        "from time import time\n",
        "\n",
        "class Trainer():\n",
        "    def __init__(self, args, logger, attack_fgsm, attack_ddn, train_attack_type =None, test_attack_type =None):\n",
        "        self.args = args\n",
        "        self.logger = logger\n",
        "        self.attack_fgsm = attack_fgsm\n",
        "        self.attack_ddn = attack_ddn\n",
        "        self.train_attack_type = train_attack_type\n",
        "        self.test_attack_type = test_attack_type\n",
        "\n",
        "\n",
        "    def standard_train(self, model, tr_loader, va_loader=None):\n",
        "        self.train(model, tr_loader, va_loader, False)\n",
        "\n",
        "    def adversarial_train(self, model, tr_loader, va_loader=None):\n",
        "        self.train(model, tr_loader, va_loader, True)\n",
        "\n",
        "    def train(self, model, tr_loader, va_loader=None, adv_train=False):\n",
        "        args = self.args\n",
        "        logger = self.logger\n",
        "\n",
        "        opt = torch.optim.SGD(model.parameters(), args.learning_rate, \n",
        "                              weight_decay=args.weight_decay,\n",
        "                              momentum=args.momentum)\n",
        "        scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, \n",
        "                                                         milestones=[40000, 60000], \n",
        "                                                         gamma=0.1)\n",
        "        _iter = 0\n",
        "\n",
        "        begin_time = time()\n",
        "\n",
        "        file_list = os.listdir(args.model_folder)\n",
        "        prev_epoch = len(file_list)\n",
        "        if prev_epoch > 0:\n",
        "            file_name = os.path.join(args.model_folder, f'checkpoint_{prev_epoch}.pth')\n",
        "            checkpoint = torch.load(file_name)\n",
        "            model.load_state_dict(checkpoint)\n",
        "            _iter = len(tr_loader) * prev_epoch - 1\n",
        "        for epoch in range(1 + prev_epoch, args.max_epoch+1):   # start at last epoch when restart \n",
        "            for data, label in tr_loader:\n",
        "                data, label = tensor2cuda(data), tensor2cuda(label)\n",
        "\n",
        "                if adv_train:\n",
        "                    # When training, the adversarial example is created from a random \n",
        "                    # close point to the original data point. If in evaluation mode, \n",
        "                    # just start from the original data point.\n",
        "                    if self.train_attack_type == \"avg\":\n",
        "                        adv_data = self.attack_fgsm.perturb(data, label, 'mean', True) + self.attack_ddn.perturb(data, label)\n",
        "                        adv_data = adv_data/2\n",
        "                    elif self.train_attack_type == \"cmplx\":\n",
        "                        adv_data = self.attack_fgsm.perturb(data, label, 'mean', True)\n",
        "                        adv_data = self.attack_ddn.perturb(adv_data, label)\n",
        "                    elif self.train_attack_type == \"fgsm\":\n",
        "                        adv_data = self.attack_fgsm.perturb(data, label, 'mean', True)  #fgsm\n",
        "                    elif self.train_attack_type == \"ddn\":\n",
        "                        adv_data = self.attack_ddn.perturb(data, label) #DDN\n",
        "                    else:\n",
        "                        raise Exception(\"Should select train attack type\")\n",
        "                    \n",
        "                    output = model(adv_data, _eval=False)\n",
        "                else:\n",
        "                    output = model(data, _eval=False)\n",
        "\n",
        "                loss = F.cross_entropy(output, label)\n",
        "\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "\n",
        "                if _iter % args.n_eval_step == 0:\n",
        "                    t1 = time()\n",
        "\n",
        "                    if adv_train:\n",
        "                        with torch.no_grad():\n",
        "                            stand_output = model(data, _eval=True)\n",
        "                        pred = torch.max(stand_output, dim=1)[1]\n",
        "                        std_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100\n",
        "\n",
        "                        pred = torch.max(output, dim=1)[1]\n",
        "                        adv_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100\n",
        "\n",
        "                    else:\n",
        "                        if self.train_attack_type == \"avg\":\n",
        "                            adv_data = self.attack_fgsm.perturb(data, label, 'mean', False) + self.attack_ddn.perturb(data, label)\n",
        "                            adv_data = adv_data/2\n",
        "                        elif self.train_attack_type == \"cmplx\":\n",
        "                            adv_data = self.attack_fgsm.perturb(data, label, 'mean', False)\n",
        "                            adv_data = self.attack_ddn.perturb(adv_data, label)\n",
        "                        elif self.train_attack_type == \"fgsm\":\n",
        "                            adv_data = self.attack_fgsm.perturb(data, label, 'mean', False)  #fgsm\n",
        "                        elif self.train_attack_type == \"ddn\":\n",
        "                            adv_data = self.attack_ddn.perturb(data, label) #DDN\n",
        "                        else:\n",
        "                            raise Exception(\"Should select train attack type\")\n",
        "\n",
        "                        with torch.no_grad():\n",
        "                            adv_output = model(adv_data)\n",
        "                        pred = torch.max(adv_output, dim=1)[1]\n",
        "                        adv_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100\n",
        "\n",
        "                        pred = torch.max(output, dim=1)[1]\n",
        "                        std_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy()) * 100\n",
        "\n",
        "                    t2 = time()\n",
        "\n",
        "                    logger.info(f'epoch: {epoch}, iter: {_iter}, lr={opt.param_groups[0][\"lr\"]}, '\n",
        "                                f'spent {time()-begin_time:.2f} s, tr_loss: {loss.item():.3f}')\n",
        "\n",
        "                    logger.info(f'standard acc: {std_acc:.3f}%, robustness acc: {adv_acc:.3f}%')\n",
        "\n",
        "                    # begin_time = time()\n",
        "\n",
        "                    # if va_loader is not None:\n",
        "                    #     va_acc, va_adv_acc = self.test(model, va_loader, True)\n",
        "                    #     va_acc, va_adv_acc = va_acc * 100.0, va_adv_acc * 100.0\n",
        "\n",
        "                    #     logger.info('\\n' + '='*30 + ' evaluation ' + '='*30)\n",
        "                    #     logger.info('test acc: %.3f %%, test adv acc: %.3f %%, spent: %.3f' % (\n",
        "                    #         va_acc, va_adv_acc, time() - begin_time))\n",
        "                    #     logger.info('='*28 + ' end of evaluation ' + '='*28 + '\\n')\n",
        "\n",
        "                    begin_time = time()\n",
        "\n",
        "                if _iter % args.n_store_image_step == 0:\n",
        "                    tv.utils.save_image(torch.cat([data.cpu(), adv_data.cpu()], dim=0), \n",
        "                                        os.path.join(args.log_folder, f'images_{_iter}.jpg'), \n",
        "                                        nrow=16)\n",
        "\n",
        "                #if _iter % args.n_checkpoint_step == 0:\n",
        "                #    file_name = os.path.join(args.model_folder, f'checkpoint_{_iter}.pth')\n",
        "                #    save_model(model, file_name)\n",
        "\n",
        "                _iter += 1\n",
        "                # scheduler depends on training interation\n",
        "                scheduler.step()\n",
        "\n",
        "            if va_loader is not None:\n",
        "                t1 = time()\n",
        "                va_acc, va_adv_acc = self.test(model, va_loader, True, False)\n",
        "                va_acc, va_adv_acc = va_acc * 100.0, va_adv_acc * 100.0\n",
        "\n",
        "                t2 = time()\n",
        "                logger.info('\\n'+'='*20 +f' evaluation at epoch: {epoch} iteration: {_iter} ' \\\n",
        "                    +'='*20)\n",
        "                logger.info(f'test acc: {va_acc:.3f}%, test adv acc: {va_adv_acc:.3f}%, spent: {t2-t1:.3f} s')\n",
        "                logger.info('='*28+' end of evaluation '+'='*28+'\\n')\n",
        "\n",
        "            file_name = os.path.join(args.model_folder, f'checkpoint_{epoch}.pth')\n",
        "            save_model(model, file_name)\n",
        "        \n",
        "        file_name = args.load_checkpoint\n",
        "        save_model(model, file_name)\n",
        "\n",
        "    def test(self, model, loader, adv_test=False, use_pseudo_label=False):\n",
        "        # adv_test is False, return adv_acc as -1 \n",
        "        total_acc = 0.0\n",
        "        num = 0\n",
        "        total_adv_acc = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, label in loader:\n",
        "                data, label = tensor2cuda(data), tensor2cuda(label)\n",
        "\n",
        "                output = model(data, _eval=True)\n",
        "\n",
        "                pred = torch.max(output, dim=1)[1]\n",
        "                te_acc = evaluate(pred.cpu().numpy(), label.cpu().numpy(), 'sum')\n",
        "                \n",
        "                total_acc += te_acc\n",
        "                num += output.shape[0]\n",
        "\n",
        "                if adv_test:\n",
        "                    # use predicted label as target label\n",
        "                    with torch.enable_grad():\n",
        "                        if self.test_attack_type == \"avg\":\n",
        "                            adv_data = self.attack_fgsm.perturb(data, label, 'mean', False) + self.attack_ddn.perturb(data, label)\n",
        "                            adv_data = adv_data/2\n",
        "                        elif self.test_attack_type == \"cmplx\":\n",
        "                            adv_data = self.attack_fgsm.perturb(data, label, 'mean', False)\n",
        "                            adv_data = self.attack_ddn.perturb(adv_data, label)\n",
        "                        elif self.test_attack_type == \"fgsm\":\n",
        "                            adv_data = self.attack_fgsm.perturb(data, label, 'mean', False)  #fgsm\n",
        "                        elif self.test_attack_type == \"ddn\":\n",
        "                            adv_data = self.attack_ddn.perturb(data, label) #DDN\n",
        "                        else:\n",
        "                            raise Exception(\"Should select test attack type\")\n",
        "\n",
        "                    adv_output = model(adv_data, _eval=True)\n",
        "\n",
        "                    adv_pred = torch.max(adv_output, dim=1)[1]\n",
        "                    adv_acc = evaluate(adv_pred.cpu().numpy(), label.cpu().numpy(), 'sum')\n",
        "                    total_adv_acc += adv_acc\n",
        "                else:\n",
        "                    total_adv_acc = -num\n",
        "\n",
        "        return total_acc / num , total_adv_acc / num"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rVzxLrHFge6"
      },
      "source": [
        "## Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLfvUcqYFicB"
      },
      "source": [
        "def main(args):\n",
        "\n",
        "    save_folder = '%s_%s' % (args.train_attack_type, args.test_attack_type)  # 저장 폴더 이름은 공격방식따라 분류\n",
        "\n",
        "    log_folder = os.path.join(args.log_root, save_folder)\n",
        "    model_folder = os.path.join(args.model_root, save_folder)\n",
        "\n",
        "    makedirs(log_folder)\n",
        "    makedirs(model_folder)\n",
        "\n",
        "    setattr(args, 'log_folder', log_folder)\n",
        "    setattr(args, 'model_folder', model_folder)\n",
        "\n",
        "    logger = create_logger(log_folder, args.todo, 'info')\n",
        "\n",
        "    print_args(args, logger)\n",
        "\n",
        "    model = GoogLeNet() # Decide model\n",
        "    attack_fgsm = FastGradientSignUntargeted(model, \n",
        "                                        args.epsilon, \n",
        "                                        args.alpha, \n",
        "                                        min_val=0, \n",
        "                                        max_val=1, \n",
        "                                        max_iters=args.k, \n",
        "                                        _type=args.perturbation_type)\n",
        "    attack_ddn = DDN(model=model, steps=args.k, device=device, gamma = args.epsilon)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        model.cuda()\n",
        "\n",
        "    trainer = Trainer(args, logger, attack_fgsm, attack_ddn, args.train_attack_type, args.test_attack_type)\n",
        "\n",
        "    if args.todo == 'train':\n",
        "        transform_train = tv.transforms.Compose([\n",
        "                tv.transforms.RandomCrop(32, padding=4, fill=0, padding_mode='constant'),\n",
        "                tv.transforms.RandomHorizontalFlip(),\n",
        "                tv.transforms.ToTensor(),\n",
        "            ])\n",
        "        tr_dataset = tv.datasets.CIFAR10(args.data_root, \n",
        "                                       train=True, \n",
        "                                       transform=transform_train, \n",
        "                                       download=True)\n",
        "\n",
        "        tr_loader = DataLoader(tr_dataset, batch_size=args.batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "        # evaluation during training\n",
        "        te_dataset = tv.datasets.CIFAR10(args.data_root, \n",
        "                                       train=False, \n",
        "                                       transform=tv.transforms.ToTensor(), \n",
        "                                       download=True)\n",
        "\n",
        "        te_loader = DataLoader(te_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "        trainer.train(model, tr_loader, te_loader, args.adv_train)\n",
        "    elif args.todo == 'test':\n",
        "        te_dataset = tv.datasets.CIFAR10(args.data_root, \n",
        "                                       train=False, \n",
        "                                       transform=tv.transforms.ToTensor(), \n",
        "                                       download=True)\n",
        "\n",
        "        te_loader = DataLoader(te_dataset, batch_size=args.batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "        checkpoint = torch.load(args.load_checkpoint)\n",
        "        model.load_state_dict(checkpoint)\n",
        "\n",
        "        std_acc, adv_acc = trainer.test(model, te_loader, adv_test=True, use_pseudo_label=False)\n",
        "\n",
        "        print(f\"std acc: {std_acc * 100:.3f}%, adv_acc: {adv_acc * 100:.3f}%\")\n",
        "\n",
        "    else:\n",
        "        raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wprKEMfVPw7-"
      },
      "source": [
        "## Do Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGnXcxGOFpHr"
      },
      "source": [
        "import easydict\n",
        "sys.argv=['']\n",
        "args = parser()\n",
        "\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTrM0EOAVp_4"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "from torch.autograd import Variable\n",
        "import math\n",
        "import torchvision.models as models\n",
        "from PIL import Image\n",
        "import copy\n",
        "from torch.autograd.gradcheck import zero_gradients\n",
        "import os\n",
        "import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm4lbIQNglZR",
        "outputId": "c6f0992b-c57e-43a0-f4ba-5199c7d5cb47"
      },
      "source": [
        "main(args)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "todo             : train\n",
            "dataset          : cifar-10\n",
            "data_root        : /gdrive/My Drive/test/data_dir\n",
            "log_root         : /gdrive/My Drive/test/log_dir\n",
            "model_root       : /gdrive/My Drive/test/checkpoint_dir\n",
            "load_checkpoint  : /gdrive/My Drive/test/model/model.pth\n",
            "affix            : default\n",
            "epsilon          : 0.0157\n",
            "alpha            : 0.00784\n",
            "k                : 10\n",
            "batch_size       : 128\n",
            "max_epoch        : 30\n",
            "learning_rate    : 0.1\n",
            "momentum         : 0.9\n",
            "weight_decay     : 0.0002\n",
            "gpu              : 0\n",
            "n_eval_step      : 100\n",
            "n_checkpoint_step : 4000\n",
            "n_store_image_step : 4000\n",
            "perturbation_type : linf\n",
            "adv_train        : True\n",
            "train_attack_type : avg\n",
            "test_attack_type : ddn\n",
            "log_folder       : /gdrive/My Drive/test/log_dir/avg_ddn\n",
            "model_folder     : /gdrive/My Drive/test/checkpoint_dir/avg_ddn\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "epoch: 8, iter: 2800, lr=0.1, spent 663.74 s, tr_loss: 1.207\n",
            "standard acc: 75.781%, robustness acc: 42.188%\n",
            "epoch: 8, iter: 2900, lr=0.1, spent 1042.47 s, tr_loss: 1.221\n",
            "standard acc: 71.875%, robustness acc: 48.438%\n",
            "epoch: 8, iter: 3000, lr=0.1, spent 1043.41 s, tr_loss: 1.129\n",
            "standard acc: 75.000%, robustness acc: 53.906%\n",
            "epoch: 8, iter: 3100, lr=0.1, spent 1044.83 s, tr_loss: 1.112\n",
            "standard acc: 76.562%, robustness acc: 49.219%\n",
            "\n",
            "==================== evaluation at epoch: 8 iteration: 3127 ====================\n",
            "test acc: 74.260%, test adv acc: 32.280%, spent: 411.452 s\n",
            "============================ end of evaluation ============================\n",
            "\n",
            "epoch: 9, iter: 3200, lr=0.1, spent 1451.13 s, tr_loss: 1.246\n",
            "standard acc: 76.562%, robustness acc: 43.750%\n",
            "epoch: 9, iter: 3300, lr=0.1, spent 1043.86 s, tr_loss: 1.185\n",
            "standard acc: 77.344%, robustness acc: 51.562%\n",
            "epoch: 9, iter: 3400, lr=0.1, spent 1040.88 s, tr_loss: 1.072\n",
            "standard acc: 82.812%, robustness acc: 50.000%\n",
            "epoch: 9, iter: 3500, lr=0.1, spent 1042.00 s, tr_loss: 1.148\n",
            "standard acc: 77.344%, robustness acc: 46.094%\n",
            "\n",
            "==================== evaluation at epoch: 9 iteration: 3518 ====================\n",
            "test acc: 74.520%, test adv acc: 34.940%, spent: 410.472 s\n",
            "============================ end of evaluation ============================\n",
            "\n",
            "epoch: 10, iter: 3600, lr=0.1, spent 1449.54 s, tr_loss: 1.088\n",
            "standard acc: 79.688%, robustness acc: 46.875%\n",
            "epoch: 10, iter: 3700, lr=0.1, spent 1043.98 s, tr_loss: 1.303\n",
            "standard acc: 73.438%, robustness acc: 45.312%\n",
            "epoch: 10, iter: 3800, lr=0.1, spent 1044.27 s, tr_loss: 1.005\n",
            "standard acc: 82.031%, robustness acc: 53.906%\n",
            "epoch: 10, iter: 3900, lr=0.1, spent 1043.78 s, tr_loss: 1.149\n",
            "standard acc: 80.469%, robustness acc: 50.000%\n",
            "\n",
            "==================== evaluation at epoch: 10 iteration: 3909 ====================\n",
            "test acc: 76.920%, test adv acc: 33.330%, spent: 410.775 s\n",
            "============================ end of evaluation ============================\n",
            "\n",
            "epoch: 11, iter: 4000, lr=0.1, spent 1449.11 s, tr_loss: 0.944\n",
            "standard acc: 89.062%, robustness acc: 53.906%\n",
            "epoch: 11, iter: 4100, lr=0.1, spent 1041.79 s, tr_loss: 1.091\n",
            "standard acc: 82.031%, robustness acc: 50.781%\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iF6gy3nGhQBQ"
      },
      "source": [
        "## Do Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Slzt-GTg-MJ"
      },
      "source": [
        "setattr(args, 'todo', 'test')\n",
        "main(args)\n",
        "# After test, please rename model.pth in model folder"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}